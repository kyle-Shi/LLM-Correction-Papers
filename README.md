# LLM-Correction-Papers
A reading list for correcting large language models 

## Collections

- **CriticBench: Benchmarking LLMs for Critique-Correct Reasoning**, 2024.02, [[paper]](http://arxiv.org/abs/2402.14809), [[repo]](https://github.com/CriticBench/CriticBench).
- **SELF: Self-Evolution with Language Feedback**, 2023.10, [[paper]](http://arxiv.org/abs/2310.00533).
- **Automatically Correcting Large Language Models: Surveying the landscape of diverse self-correction strategies**, 2023.08, [[paper]](http://arxiv.org/abs/2308.03188).
- LARGE LANGUAGE MODELS CANNOT SELF-CORRECT REASONING YET [[paper]](https://arxiv.org/pdf/2310.01798).
- Reasons to Reject? Aligning Language Models with Judgments„ÄÅ
- Self-Rewarding Language Models [[paper]](https://arxiv.org/pdf/2402.13764)
- LLM Critics Help Catch LLM Bugs [[paper]](https://cdn.openai.com/llm-critics-help-catch-llm-bugs-paper.pdf)
- GPT-CRITIC: OFFLINE REINFORCEMENT LEARNING FOR END-TO-END TASK-ORIENTED DIALOGUE SYSTEMS [[paper]](https://openreview.net/pdf?id=qaxhBG1UUaS)
- Automatically Correcting Large Language Models: Surveying the landscape of diverse self-correction strategies [[paper]](https://arxiv.org/pdf/2308.03188)
- CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing [[paper]](https://arxiv.org/pdf/2305.11738)
- Shepherd: A Critic for Language Model Generation [[paper]](https://arxiv.org/abs/2308.04592)
- Self-contrast: Better reflection through inconsistent solving perspectives.
- The Critique of Critique [[paper]](The Critique of Critique)
- 
